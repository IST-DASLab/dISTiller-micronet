version: 1
lr_schedulers:
  # Learning rate decay scheduler
  training_lr:
    class: StepLR
    gamma: 0.2
    step_size: 60

policies:
  - lr_scheduler:
      instance_name: training_lr
    starting_epoch: 0
    ending_epoch: 180
    frequency: 1
